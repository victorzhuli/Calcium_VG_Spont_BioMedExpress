{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1490136395.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to victor.li.zhu@rutgers.edu and will expire on October 06, 2017.\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "from graphlab import SArray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from itertools import cycle\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# given the l2-norm penalty weight and feature type, \n",
    "# plot the ROC for each window length, and shift each subject for testing data\n",
    "# average ROC data across subjects for each window length\n",
    "\n",
    "# input parameters\n",
    "#=================================\n",
    "classifier_list = ['KNN']\n",
    "#=================================\n",
    "\n",
    "window_length_list = [250] #, 200, 250, 300]\n",
    "window_step = 50\n",
    "feature_type_list = [1] #,2,3,12,13,23,123]  # 1: dg, 2: cc, 3: pl, 12: dg+cc, 13: dg+pl, 23: cc+pl, 123: dg+cc+pl\n",
    "k    = 9\n",
    "\n",
    "for win_ln_idx in range(len(window_length_list)): # NOTE HERE!!!!! REMOVE \"1\" AFTER THIS SESSION!!!!!!!!!!!!!\n",
    "    window_length = window_length_list[win_ln_idx]\n",
    "\n",
    "    # print on screen: progress\n",
    "    current_progress = (\"\\n========================================\\nLoading features for window_length%03d ...\\n\" \\\n",
    "                        % (window_length))\n",
    "    print current_progress\n",
    "    \n",
    "    for feature_type_idx in range(len(feature_type_list)):\n",
    "        feature_type = feature_type_list[feature_type_idx]\n",
    "        \n",
    "        colors = ['steelblue', 'orangered','gold','purple','yellowgreen','deepskyblue','firebrick']\n",
    "\n",
    "        FP = []\n",
    "        TP = []\n",
    "        \n",
    "        for mouse_id_test in range(1,3):\n",
    "            \n",
    "            ##========================= load features\n",
    "            # load and organize feature matrix\n",
    "            comb_train, comb_test = lz_load_feature_matrix_across_subject(mouse_id_test, window_length, window_step)   \n",
    "\n",
    "            results = lz_KNN_across_subjects_AC_SE_SP(comb_train, comb_test, feature_type, k)\n",
    "                        \n",
    "            roc = results['roc_curve']\n",
    "            \n",
    "            FP.append(roc['fpr'])\n",
    "            TP.append(roc['tpr'])\n",
    "            \n",
    "        FP = np.array(FP)\n",
    "        TP = np.array(TP)\n",
    "        \n",
    "        print (\"==========\\n\")\n",
    "        print FP.shape\n",
    "        print (\"==========\\n\")\n",
    "\n",
    "\n",
    "        FP_mn = np.mean(FP, axis = 0)\n",
    "        TP_mn = np.mean(TP, axis = 0)\n",
    "        AUC_mn= metrics.auc(TP_mn, FP_mn)\n",
    "        \n",
    "        print (\"==============================\\n\")\n",
    "        print FP_mn\n",
    "        print (\"==============================\\n\")\n",
    "\n",
    "        line, = plt.plot(FP_mn, TP_mn, '-', label= 'WinLn: %03d, Feature: %03d, AUC = %f' % (window_length, feature_type, AUC_mn), linewidth=3 , color = colors[feature_type_idx])\n",
    "        # Print the AUC\n",
    "        print (\"For Window Lenght %03d, feature type %03d, AUC = %f\" % (window_length, feature_type, AUC_mn))\n",
    "\n",
    "# naive classifier\n",
    "print (\"\\nCreating curve for naive classifier ...\")\n",
    "\n",
    "comb_full = comb_train.append(comb_test)\n",
    "targets = comb_full['Whisker']\n",
    "predictions = [0] * len(targets)\n",
    "predictions = SArray(predictions)\n",
    "roc_curve =  gl.evaluation.roc_curve(targets, predictions)\n",
    "FP = roc_curve['fpr']\n",
    "TP = roc_curve['tpr']\n",
    "\n",
    "plt.plot(FP, TP, '-.', label='Naive Classifier', linewidth=3)\n",
    "  \n",
    "# leg = plt.legend(loc='lower right')\n",
    "# for legobj in leg.legendHandles:\n",
    "#     legobj.set_linewidth(2.0)\n",
    "\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load and organize feature matrix\n",
    "def lz_load_feature_matrix_across_subject(mouse_id_test, window_length, window_step):\n",
    "    # the mouse_id is the one that saved for the testing set\n",
    "    # the mice other than the mouse_id are used for the training set\n",
    "    # return combined train and testing data if \"mouse_id == 0\"\n",
    "    \n",
    "    mouse_id_full = range(1,7)\n",
    "    mouse_id_trian = np.delete(mouse_id_full, mouse_id_test-1)\n",
    "    mouse_id_train = list(mouse_id_trian)\n",
    "    \n",
    "    # load training dataset\n",
    "    idx = 0\n",
    "    for mouse_id_load in mouse_id_train:\n",
    "        idx = idx + 1\n",
    "        fileName = \"format4ML_GC6f_emx_0\" + str(mouse_id_load) + \"_windowLen\" + str(window_length) + \"_winStep_0\" + str(window_step) + \"_v2_threshold_10.csv\"\n",
    "        loadPath = \"/Users/lizhu/Dropbox/projects/calcium/format4ML/\" + fileName\n",
    "\n",
    "        comb = gl.SFrame.read_csv(loadPath, delimiter=',',header=False,verbose = False)\n",
    "        colName_dg = 'degree'\n",
    "        colName_dg = gl.SArray([colName_dg + repr(i+1) for i in range(30)])\n",
    "        colName_cc = 'clusteringCoef'\n",
    "        colName_cc = gl.SArray([colName_cc + repr(i+1) for i in range(30)])\n",
    "        colName_pl = 'pathlength'\n",
    "        colName_pl = gl.SArray([colName_pl + repr(i+1) for i in range(30)])\n",
    "        colName = colName_dg.append(colName_cc.append(colName_pl.append(gl.SArray(['Whisker']))))\n",
    "        colName = (list(colName))\n",
    "        dictionary = dict(zip(comb.column_names(), colName))\n",
    "        comb = comb.rename(dictionary)\n",
    "        comb = gl.toolkits.cross_validation.shuffle(comb, random_seed=1)\n",
    "        \n",
    "        if idx == 1:\n",
    "            comb_train = comb\n",
    "        else:\n",
    "            comb_train = comb_train.append(comb)\n",
    "                    \n",
    "    # load testing dataset\n",
    "    if mouse_id_test == 0:\n",
    "        mouse_id_test = 6\n",
    "        \n",
    "    fileName = \"format4ML_GC6f_emx_0\" + str(mouse_id_test) + \"_windowLen\" + str(window_length) + \"_winStep_0\" + str(window_step) + \"_v2_threshold_10.csv\"\n",
    "    loadPath = \"/Users/lizhu/Dropbox/projects/calcium/format4ML/\" + fileName\n",
    "\n",
    "    comb = gl.SFrame.read_csv(loadPath, delimiter=',',header=False,verbose = False)\n",
    "    colName_dg = 'degree'\n",
    "    colName_dg = gl.SArray([colName_dg + repr(i+1) for i in range(30)])\n",
    "    colName_cc = 'clusteringCoef'\n",
    "    colName_cc = gl.SArray([colName_cc + repr(i+1) for i in range(30)])\n",
    "    colName_pl = 'pathlength'\n",
    "    colName_pl = gl.SArray([colName_pl + repr(i+1) for i in range(30)])\n",
    "    colName = colName_dg.append(colName_cc.append(colName_pl.append(gl.SArray(['Whisker']))))\n",
    "    colName = (list(colName))\n",
    "    dictionary = dict(zip(comb.column_names(), colName))\n",
    "    comb = comb.rename(dictionary)\n",
    "    comb_test = gl.toolkits.cross_validation.shuffle(comb, random_seed=1)\n",
    "        \n",
    "    if mouse_id_test != 0:\n",
    "        return comb_train, comb_test\n",
    "    else:\n",
    "        comb_full = comb_train.append(comb_test)\n",
    "        print type(comb_full)\n",
    "        return comb_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train and cross-validation\n",
    "def lz_KNN_across_subjects_AC_SE_SP(data_train, data_test, feature_type, k):\n",
    "    \n",
    "    # clearify features\n",
    "    feature_dg = data_train.column_names()[0:30] # feature 1~30: degree, 31~60: clustering coefficient, 60~90: pathlength\n",
    "    feature_cc = data_train.column_names()[30:60]\n",
    "    feature_pl = data_train.column_names()[60:90]\n",
    "    \n",
    "    if feature_type == 1:   feature = feature_dg\n",
    "    if feature_type == 2:   feature = feature_cc\n",
    "    if feature_type == 3:   feature = feature_pl\n",
    "    if feature_type == 12:  feature = feature_dg + feature_cc\n",
    "    if feature_type == 13:  feature = feature_dg + feature_pl\n",
    "    if feature_type == 23:  feature = feature_cc + feature_pl\n",
    "    if feature_type == 123: feature = feature_dg + feature_cc + feature_pl\n",
    "     \n",
    "    m = gl.nearest_neighbor_classifier.create(data_train,\n",
    "                                              target = 'Whisker',\n",
    "                                              features = feature,\n",
    "                                              distance = 'euclidean',\n",
    "                                              verbose = False)\n",
    "\n",
    "    results = m.evaluate(data_test, max_neighbors = k)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lz_extract_ACC_SE_SP(confusion_matrix):\n",
    "    TP = confusion_matrix[(confusion_matrix['target_label']==1) & (confusion_matrix['predicted_label']==1)]\n",
    "    if np.size(TP) == 0:\n",
    "        TP = 0\n",
    "    else:\n",
    "        TP = TP['count'][0]\n",
    "    TN = confusion_matrix[(confusion_matrix['target_label']==0) & (confusion_matrix['predicted_label']==0)]\n",
    "    if np.size(TN) == 0:\n",
    "        TN = 0\n",
    "    else:\n",
    "        TN = TN['count'][0]\n",
    "    FP = confusion_matrix[(confusion_matrix['target_label']==0) & (confusion_matrix['predicted_label']==1)]\n",
    "    if np.size(FP) == 0:\n",
    "        FP = 0\n",
    "    else:\n",
    "        FP = FP['count'][0]\n",
    "    FN = confusion_matrix[(confusion_matrix['target_label']==1) & (confusion_matrix['predicted_label']==0)]\n",
    "    if np.size(FN) == 0:\n",
    "        FN = 0\n",
    "    else:\n",
    "        FN = FN['count'][0]\n",
    "    \n",
    "    return TP, TN, FP, FN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
