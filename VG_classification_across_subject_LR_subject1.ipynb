{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1489207839.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to victor.li.zhu@rutgers.edu and will expire on October 06, 2017.\n"
     ]
    }
   ],
   "source": [
    "import graphlab as gl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Loading features for testing mouse01, window_length100 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# input parameters\n",
    "#=================================\n",
    "classifier_list = ['LR']\n",
    "#=================================\n",
    "\n",
    "window_length_list = [100, 150, 200, 250, 300]\n",
    "window_step = 50\n",
    "feature_type_list = [1, 2, 3, 12, 13, 23, 123]  # 1: dg, 2: cc, 3: pl, 12: dg+cc, 13: dg+pl, 23: cc+pl, 123: dg+cc+pl\n",
    "l2_penalty_list = np.logspace(-2, 1.5, num=15, endpoint=True, base=10.0, dtype=None).tolist()\n",
    "l1_penalty = 0.0\n",
    "\n",
    "for mouse_id_test in range(1,2):\n",
    "\n",
    "    for win_ln_idx in range(len(window_length_list)): # NOTE HERE!!!!! REMOVE \"1\" AFTER THIS SESSION!!!!!!!!!!!!!\n",
    "        window_length = window_length_list[win_ln_idx]\n",
    "        \n",
    "        ##========================= load features\n",
    "        # print on screen: progress\n",
    "        current_progress = (\"\\n========================================\\nLoading features for testing mouse%02d, window_length%03d ...\\n\" \\\n",
    "                            % (mouse_id_test, window_length))\n",
    "        print current_progress\n",
    "\n",
    "        # load and organize feature matrix\n",
    "        comb_train, comb_test = lz_load_feature_matrix_across_subject(mouse_id_test, window_length, window_step)       \n",
    "        \n",
    "        for classifier_idx in range(len(classifier_list)):\n",
    "            classifier = classifier_list[classifier_idx]\n",
    "\n",
    "            # initiate\n",
    "            AC = [[0] * len(l2_penalty_list) for _ in range(len(feature_type_list))] \n",
    "            SE = [[0] * len(l2_penalty_list) for _ in range(len(feature_type_list))] \n",
    "            SP = [[0] * len(l2_penalty_list) for _ in range(len(feature_type_list))] \n",
    "\n",
    "            for feature_type_idx in range(len(feature_type_list)):\n",
    "                feature_type = feature_type_list[feature_type_idx]\n",
    "\n",
    "                ##========================= classification\n",
    "                for l2_penalty_idx in range(len(l2_penalty_list)):\n",
    "                    l2_penalty = l2_penalty_list[l2_penalty_idx]\n",
    "\n",
    "                    # print on screen: progress\n",
    "                    current_progress = (\"\\n----------------------------------------\\nClassifying --> classifier: %s, feature_type%03d, l2_penalty_%f ...\" \\\n",
    "                                        % (classifier, feature_type, l2_penalty))\n",
    "                    print current_progress\n",
    "\n",
    "                    if classifier == 'LR':\n",
    "                        AC[feature_type_idx][l2_penalty_idx],SE[feature_type_idx][l2_penalty_idx],SP[feature_type_idx][l2_penalty_idx] = \\\n",
    "                            lz_logistic_across_subjects_AC_SE_SP(comb_train, comb_test, feature_type, l2_penalty, l1_penalty)\n",
    "                    if classifier == 'SVM':\n",
    "                        AC[feature_type_idx][l2_penalty_idx],SE[feature_type_idx][l2_penalty_idx],SP[feature_type_idx][l2_penalty_idx] = \\\n",
    "                            lz_svm_across_subjects_AC_SE_SP(comb_train, comb_test, feature_type, l2_penalty)\n",
    "                    # if classifier == 'RF'\n",
    "                        # ...\n",
    "                    # if classifier == 'KNN'\n",
    "                        # ...\n",
    "\n",
    "            ##====================== save results\n",
    "            AC_saveName = (\"%s_across_subject_test_mouse%02d_window_length%03d_AC.csv\" \\\n",
    "                           % (classifier,mouse_id_test,window_length))\n",
    "            SE_saveName = (\"%s_across_subject_test_mouse%02d_window_length%03d_SE.csv\" \\\n",
    "                           % (classifier,mouse_id_test,window_length))\n",
    "            SP_saveName = (\"%s_across_subject_test_mouse%02d_window_length%03d_SP.csv\" \\\n",
    "                           % (classifier,mouse_id_test,window_length))\n",
    "            df_AC = pd.DataFrame(AC)\n",
    "            df_SE = pd.DataFrame(SE)        \n",
    "            df_SP = pd.DataFrame(SP)  \n",
    "            \n",
    "            os.chdir(\"/Users/lizhu/Dropbox/projects/calcium/classification_result/across_subject\") \n",
    "            df_AC.to_csv(AC_saveName, index = False, header = False)\n",
    "            df_SE.to_csv(SE_saveName, index = False, header = False)\n",
    "            df_SP.to_csv(SP_saveName, index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load and organize feature matrix\n",
    "def lz_load_feature_matrix_across_subject(mouse_id_test, window_length, window_step):\n",
    "    # the mouse_id is the one that saved for the testing set\n",
    "    # the mice other than the mouse_id are used for the training set\n",
    "    \n",
    "    mouse_id_full = range(1,7)\n",
    "    mouse_id_trian = np.delete(mouse_id_full, mouse_id_test-1)\n",
    "    mouse_id_train = list(mouse_id_trian)\n",
    "    \n",
    "    # load training dataset\n",
    "    idx = 0\n",
    "    for mouse_id_load in mouse_id_train:\n",
    "        idx = idx + 1\n",
    "        fileName = \"format4ML_GC6f_emx_0\" + str(mouse_id_load) + \"_windowLen\" + str(window_length) + \"_winStep_0\" + str(window_step) + \"_v2_threshold_10.csv\"\n",
    "        loadPath = \"/Users/lizhu/Dropbox/projects/calcium/format4ML/\" + fileName\n",
    "#         current_progress = (\"\\n----------------------------------------\\nloaded--> mouse_id: %s ...\" \\\n",
    "#                                         % (mouse_id_load))\n",
    "#         print current_progress\n",
    "        comb = gl.SFrame.read_csv(loadPath, delimiter=',',header=False,verbose = False)\n",
    "        colName_dg = 'degree'\n",
    "        colName_dg = gl.SArray([colName_dg + repr(i+1) for i in range(30)])\n",
    "        colName_cc = 'clusteringCoef'\n",
    "        colName_cc = gl.SArray([colName_cc + repr(i+1) for i in range(30)])\n",
    "        colName_pl = 'pathlength'\n",
    "        colName_pl = gl.SArray([colName_pl + repr(i+1) for i in range(30)])\n",
    "        colName = colName_dg.append(colName_cc.append(colName_pl.append(gl.SArray(['Whisker']))))\n",
    "        colName = (list(colName))\n",
    "        dictionary = dict(zip(comb.column_names(), colName))\n",
    "        comb = comb.rename(dictionary)\n",
    "        comb = gl.toolkits.cross_validation.shuffle(comb, random_seed=1)\n",
    "        # comb_train['Whisker'].show(view = 'Categorical')\n",
    "        \n",
    "        if idx == 1:\n",
    "            comb_train = comb\n",
    "        else:\n",
    "            comb_train = comb_train.append(comb)\n",
    "                    \n",
    "    # load testing dataset\n",
    "    fileName = \"format4ML_GC6f_emx_0\" + str(mouse_id_test) + \"_windowLen\" + str(window_length) + \"_winStep_0\" + str(window_step) + \"_v2_threshold_10.csv\"\n",
    "    loadPath = \"/Users/lizhu/Dropbox/projects/calcium/format4ML/\" + fileName\n",
    "#     current_progress = (\"\\n----------------------------------------\\nloaded--> mouse_id: %s ...\" \\\n",
    "#                                         % (mouse_id_test))\n",
    "#     print current_progress\n",
    "    comb = gl.SFrame.read_csv(loadPath, delimiter=',',header=False,verbose = False)\n",
    "    colName_dg = 'degree'\n",
    "    colName_dg = gl.SArray([colName_dg + repr(i+1) for i in range(30)])\n",
    "    colName_cc = 'clusteringCoef'\n",
    "    colName_cc = gl.SArray([colName_cc + repr(i+1) for i in range(30)])\n",
    "    colName_pl = 'pathlength'\n",
    "    colName_pl = gl.SArray([colName_pl + repr(i+1) for i in range(30)])\n",
    "    colName = colName_dg.append(colName_cc.append(colName_pl.append(gl.SArray(['Whisker']))))\n",
    "    colName = (list(colName))\n",
    "    dictionary = dict(zip(comb.column_names(), colName))\n",
    "    comb = comb.rename(dictionary)\n",
    "    comb_test = gl.toolkits.cross_validation.shuffle(comb, random_seed=1)\n",
    "        \n",
    "    \n",
    "    return comb_train, comb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train and cross-validation\n",
    "def lz_logistic_across_subjects_AC_SE_SP(data_train, data_test, feature_type, l2_penalty, l1_penalty):\n",
    "    \n",
    "    # clearify features\n",
    "    feature_dg = data_train.column_names()[0:30] # feature 1~30: degree, 31~60: clustering coefficient, 60~90: pathlength\n",
    "    feature_cc = data_train.column_names()[30:60]\n",
    "    feature_pl = data_train.column_names()[60:90]\n",
    "    \n",
    "    if feature_type == 1:   feature = feature_dg\n",
    "    if feature_type == 2:   feature = feature_cc\n",
    "    if feature_type == 3:   feature = feature_pl\n",
    "    if feature_type == 12:  feature = feature_dg + feature_cc\n",
    "    if feature_type == 13:  feature = feature_dg + feature_pl\n",
    "    if feature_type == 23:  feature = feature_cc + feature_pl\n",
    "    if feature_type == 123: feature = feature_dg + feature_cc + feature_pl\n",
    "\n",
    "    m = gl.logistic_classifier.create(data_train,\n",
    "                                      target='Whisker',\n",
    "                                      features=feature,\n",
    "                                      l2_penalty = l2_penalty, \n",
    "                                      l1_penalty = l1_penalty,\n",
    "                                      validation_set=None,\n",
    "                                      verbose = False)\n",
    "    confusion_matrix = m.evaluate(data_test, 'confusion_matrix')\n",
    "    confusion_matrix = confusion_matrix.values()[0]\n",
    "\n",
    "    TP, TN, FP, FN = lz_extract_ACC_SE_SP(confusion_matrix)\n",
    "\n",
    "    SP = float(TN) / (TN + FP)\n",
    "    SE = float(TP) / (TP + FN)\n",
    "    AC = float(TP+TN) / (TP+TN+FP+FN)\n",
    "    \n",
    "    print 'AC = ', AC\n",
    "    print 'SE = ', SE\n",
    "    print 'SP = ', SP\n",
    "    \n",
    "    return AC, SE, SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lz_extract_ACC_SE_SP(confusion_matrix):\n",
    "    TP = confusion_matrix[(confusion_matrix['target_label']==1) & (confusion_matrix['predicted_label']==1)]\n",
    "    if np.size(TP) == 0:\n",
    "        TP = 0\n",
    "    else:\n",
    "        TP = TP['count'][0]\n",
    "    TN = confusion_matrix[(confusion_matrix['target_label']==0) & (confusion_matrix['predicted_label']==0)]\n",
    "    if np.size(TN) == 0:\n",
    "        TN = 0\n",
    "    else:\n",
    "        TN = TN['count'][0]\n",
    "    FP = confusion_matrix[(confusion_matrix['target_label']==0) & (confusion_matrix['predicted_label']==1)]\n",
    "    if np.size(FP) == 0:\n",
    "        FP = 0\n",
    "    else:\n",
    "        FP = FP['count'][0]\n",
    "    FN = confusion_matrix[(confusion_matrix['target_label']==1) & (confusion_matrix['predicted_label']==0)]\n",
    "    if np.size(FN) == 0:\n",
    "        FN = 0\n",
    "    else:\n",
    "        FN = FN['count'][0]\n",
    "    \n",
    "    return TP, TN, FP, FN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
